# -*- coding: utf-8 -*-
"""Keras_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/143UDQmaRPmdrihe5ZCmPsiu5pA4M4iJR
"""

!pip install tensorflow numpy mnist

!pip install tensorflow numpy mnist
import numpy as np
from tensorflow import keras

# Load the MNIST dataset using keras.datasets
(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()

print(train_images.shape)  # (60000, 28, 28)
print(train_labels.shape)  # (60000,)

import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras

# Load the MNIST dataset
(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()

# Visualize the first 5 images in the training set
fig = plt.figure(figsize=(20, 10))
for i in range(5):  # Chỉ hiển thị 5 ảnh đầu tiên
    fig.add_subplot(1, 5, i+1)  # Tạo lưới 1x5
    plt.imshow(train_images[i], cmap='gray')  # Hiển thị ảnh dưới dạng grayscale
    plt.title(f"Label: {train_labels[i]}")  # Hiển thị nhãn tương ứng
    plt.axis('off')  # Tắt hiển thị trục
plt.show()

import numpy as np
from tensorflow import keras

# Load the MNIST dataset using keras.datasets
(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()

# Normalize the images.
train_images = (train_images / 255) - 0.5
test_images = (test_images / 255) - 0.5

# Reshape the images.
train_images = np.expand_dims(train_images, axis=3)
test_images = np.expand_dims(test_images, axis=3)

print(train_images.shape) # (60000, 28, 28, 1)
print(test_images.shape)  # (10000, 28, 28, 1)



from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, ReLU

# Build the updated model.
model = Sequential([
    # Convolutional Layer 1
    Conv2D(32, kernel_size=3, strides=1, padding='same', input_shape=(28, 28, 1)),
    ReLU(),
    MaxPooling2D(pool_size=2, strides=2),

    # Convolutional Layer 2
    Conv2D(64, kernel_size=3, strides=1, padding='same'),
    ReLU(),
    MaxPooling2D(pool_size=2, strides=2),

    # Flatten the feature maps
    Flatten(),

    # Fully Connected Layer 1
    Dense(128),
    ReLU(),
    Dropout(0.5),

    # Fully Connected Layer 2 (Output Layer)
    Dense(10, activation='softmax')
])

# Compile the model.
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Print the model summary.
model.summary()

model.compile(
  'adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)

# Instead of using the 'mnist' library, use Keras to load the data:
from tensorflow import keras

(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()

print(train_labels[0])  # 5

from tensorflow.keras.utils import to_categorical

model.fit(
  train_images,
  to_categorical(train_labels),
  epochs=3,
  validation_data=(test_images, to_categorical(test_labels)),
)

# Import the necessary modules
import h5py
import os
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, ReLU

# Define the filename of the HDF5 file
h5_filename = 'cnn.weights.h5'


model = Sequential([
    # Convolutional Layer 1
    Conv2D(32, kernel_size=3, strides=1, padding='same', input_shape=(28, 28, 1)),
    ReLU(),
    MaxPooling2D(pool_size=2, strides=2),

    # Convolutional Layer 2
    Conv2D(64, kernel_size=3, strides=1, padding='same'),
    ReLU(),
    MaxPooling2D(pool_size=2, strides=2),

    # Flatten the feature maps
    Flatten(),

    # Fully Connected Layer 1
    Dense(128),
    ReLU(),
    Dropout(0.5),

    # Fully Connected Layer 2 (Output Layer)
    Dense(10, activation='softmax')
])

# Compile the model.
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])


# Check if the file exists and if it is open
try:
    # Attempt to open the file in read mode
    with h5py.File(h5_filename, 'r'):
        # If successful, the file is already open
        print(f"File '{h5_filename}' is already open. Closing it...")

    # Close the file if it was open
    os.system(f"fuser -k {h5_filename}") # This command kills any process using the file

except OSError:
    # If the file is not open or doesn't exist, proceed with saving
    print(f"File '{h5_filename}' is not open or does not exist. Saving weights...")

# Save the model weights
model.save_weights(h5_filename)
print(f"Model weights saved to '{h5_filename}'")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, ReLU

# Build the updated model.
model = Sequential([
    # Convolutional Layer 1
    Conv2D(32, kernel_size=3, strides=1, padding='same', input_shape=(28, 28, 1)),
    ReLU(),
    MaxPooling2D(pool_size=2, strides=2),

    # Convolutional Layer 2
    Conv2D(64, kernel_size=3, strides=1, padding='same'),
    ReLU(),
    MaxPooling2D(pool_size=2, strides=2),

    # Flatten the feature maps
    Flatten(),

    # Fully Connected Layer 1
    Dense(128),
    ReLU(),
    Dropout(0.5),

    # Fully Connected Layer 2 (Output Layer)
    Dense(10, activation='softmax')
])

# Load the model's saved weights.
model.load_weights('cnn.weights.h5')

# Now, make predictions
predictions = model.predict(test_images[:5])
print(np.argmax(predictions, axis=1))  # Print predicted labels
print(test_labels[:5])  # Print actual labels for comparison